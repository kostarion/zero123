{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/admin/home-dmitry/venvs/zero123_vanilla/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import webdataset as wds\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from einops import rearrange\n",
    "from ldm.util import instantiate_from_config\n",
    "from datasets import load_dataset\n",
    "import pytorch_lightning as pl\n",
    "import copy\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import json\n",
    "import os, sys\n",
    "import webdataset as wds\n",
    "import io\n",
    "import tarfile\n",
    "import math\n",
    "import re\n",
    "from safetensors.torch import load as load_sftr, load_file as load_sftr_file\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedObjaverseData(Dataset):\n",
    "    def __init__(self,\n",
    "        root_dir='.objaverse/hf-objaverse-v1/views',\n",
    "        data_config_file=None,\n",
    "        load_tensors=False,\n",
    "        image_transforms=[],\n",
    "        postprocess=None,\n",
    "        return_paths=False,\n",
    "        total_view=54,\n",
    "        use_canonical_views=True,\n",
    "        num_canonical_views=6,\n",
    "        color0_prob=0.5,\n",
    "        cond_polar_thr=180,\n",
    "        elevation_cond=False,\n",
    "        elevation_std=10.0,\n",
    "        validation=False,\n",
    "        ) -> None:\n",
    "        \"\"\"Create a dataset from a folder of images.\n",
    "        If you pass in a root directory it will be searched for images\n",
    "        ending in ext (ext can be a list)\n",
    "        \"\"\"\n",
    "        print(\"********** \", root_dir)\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.return_paths = return_paths\n",
    "        if isinstance(postprocess, DictConfig):\n",
    "            postprocess = instantiate_from_config(postprocess)\n",
    "        self.postprocess = postprocess\n",
    "        self.total_view = total_view\n",
    "        self.use_canonical_views = use_canonical_views\n",
    "        self.num_canonical_views = num_canonical_views\n",
    "        self.color0_prob = color0_prob\n",
    "        self.cond_polar_thr = cond_polar_thr\n",
    "        self.load_tensors = load_tensors\n",
    "        self.elevation_cond = elevation_cond\n",
    "        self.elevation_std = elevation_std\n",
    "\n",
    "        data_config_path = data_config_file if data_config_file else os.path.join(root_dir, 'data_config.json')\n",
    "        with open(data_config_path) as f:\n",
    "            self.paths = json.load(f)\n",
    "            \n",
    "        total_objects = len(self.paths)\n",
    "        if validation:\n",
    "            self.paths = self.paths # [math.floor(total_objects / 100. * 99.):] # used last 1% as validation\n",
    "            import random\n",
    "            random.shuffle(self.paths)\n",
    "        else:\n",
    "            self.paths = self.paths[:math.floor(total_objects / 100. * 99.)] # used first 99% as training\n",
    "        print('============= length of dataset %d =============' % len(self.paths))\n",
    "        self.tform = image_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def load_img(self, object_storage, index, fname_format_str='rgba/rgba_{view_index:04d}.png'):\n",
    "        img_fname = f'{fname_format_str.format(view_index=index)}'\n",
    "        if isinstance(object_storage, tarfile.TarFile):\n",
    "            object_name = object_storage.getnames()[0]\n",
    "            image = object_storage.extractfile(f'{object_name}/{img_fname}').read()\n",
    "            image = Image.open(io.BytesIO(image)).convert('RGBA')\n",
    "        else:\n",
    "            image = Image.open(os.path.join(object_storage, img_fname)).convert('RGBA')\n",
    "        return image\n",
    "    \n",
    "    def load_tensor(self, object_storage, index, color_idx=0,\n",
    "                    fname_format_str='view-{view_index:03d}-c{color_idx:02d}.sftr', key='vae_latent'):\n",
    "        tensor_fname = f'{fname_format_str.format(view_index=index, color_idx=color_idx)}'\n",
    "        if isinstance(object_storage, tarfile.TarFile):\n",
    "            object_name = object_storage.getnames()[0]\n",
    "            tensor = object_storage.extractfile(f'{object_name}/{tensor_fname}').read()\n",
    "            tensor = load_sftr(tensor)[key]\n",
    "        else:\n",
    "            tensor = load_sftr_file(os.path.join(object_storage, tensor_fname))[key]\n",
    "        return tensor\n",
    "\n",
    "    def load_viewpoint(self, object_storage, index, prefix='frame_'):\n",
    "        metas_fname = f'{prefix}{index:04d}.json'\n",
    "        if isinstance(object_storage, tarfile.TarFile):\n",
    "            object_name = object_storage.getnames()[0]\n",
    "            metas = object_storage.extractfile(f'{object_name}/{metas_fname}').read()\n",
    "            metas = json.loads(metas)\n",
    "        else:\n",
    "            with open(os.path.join(object_storage, metas_fname), 'r') as f:\n",
    "                metas = json.loads(f.read())\n",
    "        polar, azimuth, r = metas[\"polar\"], metas[\"azimuth\"], metas[\"r\"]\n",
    "        return polar, azimuth, r\n",
    "\n",
    "    def process_img(self, img, background_color=(255, 255, 255)):\n",
    "        background = Image.new('RGBA', img.size, background_color)\n",
    "        img = Image.alpha_composite(background, img).convert(\"RGB\")\n",
    "        return self.tform(img) if self.tform else img\n",
    "\n",
    "    def get_T(self, object_storage, index_target, index_cond):\n",
    "        target_polar, target_azimuth, target_r = self.load_viewpoint(object_storage, index_target)\n",
    "        cond_polar, cond_azimuth, cond_r = self.load_viewpoint(object_storage, index_cond)\n",
    "        \n",
    "        d_polar = target_polar - cond_polar\n",
    "        d_azimuth = (target_azimuth - cond_azimuth) % (2 * math.pi)\n",
    "        d_r = target_r - cond_r\n",
    "        \n",
    "        if self.elevation_cond:\n",
    "            randomized_polar_cond = np.clip(np.random.normal(cond_polar, self.elevation_std / 180. * math.pi), 0, math.pi)\n",
    "            d_T = torch.tensor([d_polar, math.sin(d_azimuth), math.cos(d_azimuth), randomized_polar_cond])\n",
    "        else:\n",
    "            d_T = torch.tensor([d_polar, math.sin(d_azimuth), math.cos(d_azimuth), d_r])\n",
    "        return d_T\n",
    "\n",
    "    def get_background_ratio(self, img):\n",
    "        return (np.array(img)[..., 3] != 0).sum() / img.height / img.width\n",
    "\n",
    "    def extract_data(self, object_storage, index_target, index_cond, color_idx=0):\n",
    "        data = {}\n",
    "        if not self.load_tensors:\n",
    "            img_target = self.load_img(object_storage, index_target)\n",
    "            img_cond = self.load_img(object_storage, index_cond)\n",
    "            data[\"image_target\"] = self.process_img(img_target)\n",
    "            data[\"image_cond\"] = self.process_img(img_cond)\n",
    "\n",
    "            data[\"background_ratio_target\"] = self.get_background_ratio(img_target)\n",
    "            data[\"background_ratio_cond\"] = self.get_background_ratio(img_cond)\n",
    "            data[\"target_polar\"], data[\"target_azimuth\"], _ = \\\n",
    "                self.load_viewpoint(object_storage, index_target)\n",
    "            data[\"cond_polar\"], data[\"cond_azimuth\"], _ = \\\n",
    "                self.load_viewpoint(object_storage, index_cond)\n",
    "        else:\n",
    "            data[\"latent_target\"] = self.load_tensor(object_storage, index_target, color_idx=color_idx)\n",
    "            data[\"latent_cond\"] = self.load_tensor(object_storage, index_cond, color_idx=color_idx)\n",
    "            data[\"clip_emb_cond\"] = self.load_tensor(\n",
    "                object_storage, index_cond, color_idx=color_idx,\n",
    "                fname_format_str='clip-{view_index:03d}-c{color_idx:02d}.sftr',\n",
    "                key='clip_emb')\n",
    "        data[\"T\"] = self.get_T(object_storage, index_target, index_cond)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def get_indices(self, object_storage, total_view):\n",
    "        available_indices = [v for v in range(total_view) if (self.use_canonical_views or v >= self.num_canonical_views)]\n",
    "        if self.cond_polar_thr > 0:\n",
    "            cond_polar_thr_rad = self.cond_polar_thr / 180. * math.pi\n",
    "            polars = [(i, self.load_viewpoint(object_storage, i)[0]) for i in available_indices]\n",
    "            polars = [p for p in polars if p[1] < cond_polar_thr_rad]\n",
    "            index_cond = random.choice(polars)[0]\n",
    "            index_target = random.choice([i for i in available_indices if i != index_cond])\n",
    "        else:\n",
    "            index_target, index_cond = random.sample(available_indices, 2)\n",
    "        return index_target, index_cond\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = {}\n",
    "        # TODO: set seed\n",
    "        object_filepath = os.path.join(self.root_dir, self.paths[index])\n",
    "        is_tar = False\n",
    "        if object_filepath.endswith('.tar'):\n",
    "            is_tar = True\n",
    "        object_name = Path(object_filepath).stem\n",
    "        if self.return_paths:\n",
    "            data[\"path\"] = str(object_filepath)\n",
    "\n",
    "        object_storage = tarfile.open(object_filepath) if is_tar else object_filepath\n",
    "        \n",
    "        total_view = self.total_view\n",
    "        object_files = object_storage.getnames() if is_tar else os.listdir(object_storage)\n",
    "        if self.load_tensors:\n",
    "            total_view = len([f for f in object_files if re.findall(r'view-(\\d+)-c00.sftr', f)])\n",
    "            total_view = min(total_view, len([f for f in object_files if re.findall(r'clip-(\\d+)-c00.sftr', f)]))\n",
    "            total_view = min(total_view, len([f for f in object_files if re.findall(r'frame_(\\d+).json', f)]))\n",
    "        else:\n",
    "            total_view = len([f for f in object_files if re.findall(r'rgba/rgba_(\\d+).png', f)])\n",
    "            total_view = min(total_view, len([f for f in object_files if re.findall(r'frame_(\\d+).json', f)]))\n",
    "\n",
    "        # TODO: remove\n",
    "        if total_view < 48:\n",
    "            print(f\"==== Invalid object {object_name} ====\")\n",
    "            return self.__getitem__((index + 1) % len(self.paths))\n",
    "\n",
    "        color_idx = 0 if random.random() < self.color0_prob else 1\n",
    "\n",
    "        try:\n",
    "            index_target, index_cond = self.get_indices(object_storage, total_view)\n",
    "            # index_target, index_cond = random.sample(range(total_view-1), 2) # without replacement\n",
    "            # index_target, index_cond = 2, 1\n",
    "            data = self.extract_data(object_storage, index_target, index_cond, color_idx=color_idx)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            print(f\"************* Invalid files {object_filepath} {index_target} {index_cond} ***************\")\n",
    "            with open(\"/fsx/proj-mod3d/dmitry/repos/zero123/zero123/invalid_files.txt\", \"a\") as f:\n",
    "                f.write(f'{object_filepath}:({index_target}, {index_cond})\\n')\n",
    "            index_target, index_cond = 1, 2\n",
    "            data = self.extract_data(object_storage, index_target, index_cond, color_idx=color_idx)\n",
    "            return self.__getitem__((index + 1) % len(self.paths))\n",
    "\n",
    "        data['object_name'] = object_name\n",
    "        data['index_target'], data['index_cond'] = index_target, index_cond\n",
    "\n",
    "        if self.postprocess is not None:\n",
    "            data = self.postprocess(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/scratch/objaverse_new_untar/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob(os.path.join(data_dir, \"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[0]) as f:\n",
    "    j = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/objaverse_new_untar/f854f5eb9d4e480f97db63805f04ee59.ffffff.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'by'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j['objaverse']['license']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_paths = []\n",
    "for path in paths:\n",
    "    with open(path) as f:\n",
    "        j = json.load(f)\n",
    "    if j['objaverse']['license'] not in ('by-nc-sa', 'by-nc', 'by-sa'):\n",
    "        valid_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040178571428571"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_paths) / len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f854f5eb9d4e480f97db63805f04ee59'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(valid_paths[0]).split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('good_objaverse_dirs.json') as f:\n",
    "    old_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches = 0\n",
    "for vpath in valid_paths:\n",
    "    base = os.path.basename(vpath).split('.')[0]\n",
    "    num_matches += base in old_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "untarred_objects = os.listdir('/scratch/objaverse_untar_2')\n",
    "with open('objaverse_filtered_by_nc.json') as f:\n",
    "    filtered_objects = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189342"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(untarred_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_present_objects = list(set(filtered_objects).intersection(set(untarred_objects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797852563086901"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "151067 / 189342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107762672835398"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_present_objects) / len(untarred_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('objaverse_filtered_by_nc_valid.json', \"w\") as f:\n",
    "    json.dump(filtered_present_objects, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero123_vanilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
